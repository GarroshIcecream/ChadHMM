{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79bc567",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chadhmm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchadhmm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianHMM, MultinomialHMM, PoissonHMM, GaussianMixtureHMM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchadhmm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transitions, CovarianceType\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chadhmm'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from chadhmm import GaussianHMM, MultinomialHMM, PoissonHMM, GaussianMixtureHMM\n",
    "from chadhmm import Transitions, CovarianceType\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1377a",
   "metadata": {},
   "source": [
    "## 1. Create a GaussianHMM Model on CPU (Default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c043898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gaussian HMM model\n",
    "n_states = 3\n",
    "n_features = 2\n",
    "\n",
    "hmm = GaussianHMM(\n",
    "    n_states=n_states,\n",
    "    n_features=n_features,\n",
    "    transitions=Transitions.ERGODIC,\n",
    "    covariance_type=CovarianceType.FULL,\n",
    "    alpha=1.0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate some test data\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, n_features)\n",
    "lengths = [50, 50]\n",
    "\n",
    "print(f\"Model created on device: {next(hmm.parameters()).device}\")\n",
    "print(f\"Data is on device: {X.device}\")\n",
    "print(f\"\\nModel parameters devices:\")\n",
    "for name, param in hmm.named_parameters():\n",
    "    print(f\"  {name}: {param.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5164449",
   "metadata": {},
   "source": [
    "## 2. Move Model to Different Devices\n",
    "\n",
    "Since HMM models inherit from `nn.Module`, you can use PyTorch's standard `.to()` method to move them between devices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available devices and select one\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_name = \"CUDA GPU\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    device_name = \"MPS (Apple Silicon)\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "print(f\"Moving model to: {device_name}\")\n",
    "\n",
    "# Move model to the selected device\n",
    "hmm.to(device)\n",
    "\n",
    "print(f\"\\nModel is now on device: {next(hmm.parameters()).device}\")\n",
    "print(f\"\\nAll model parameters after moving:\")\n",
    "for name, param in hmm.named_parameters():\n",
    "    print(f\"  {name}: {param.device}, shape: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cb690",
   "metadata": {},
   "source": [
    "## 3. Train Model on the Target Device\n",
    "\n",
    "When training, make sure your data is also on the same device as the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to the same device as the model\n",
    "X_device = X.to(device)\n",
    "\n",
    "print(f\"Data moved to device: {X_device.device}\")\n",
    "\n",
    "# Train the model\n",
    "hmm.fit(\n",
    "    X=X_device,\n",
    "    lengths=lengths,\n",
    "    max_iter=10,\n",
    "    n_init=1,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\nModel trained successfully on {device_name}!\")\n",
    "print(f\"Final log-likelihood: {hmm.score(X_device, lengths=lengths, by_sample=False).item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7aa66f",
   "metadata": {},
   "source": [
    "## 4. Move Model Back to CPU\n",
    "\n",
    "After training on GPU, you might want to move the model back to CPU for inference or saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d846f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model back to CPU\n",
    "hmm.to('cpu')\n",
    "\n",
    "print(f\"Model moved back to: {next(hmm.parameters()).device}\")\n",
    "\n",
    "# Move data back to CPU for inference\n",
    "X_cpu = X_device.to('cpu')\n",
    "\n",
    "# Perform inference on CPU\n",
    "predictions = hmm.predict(X_cpu, lengths=lengths)\n",
    "print(f\"\\nPredictions shape: {len(predictions)} sequences\")\n",
    "print(f\"First sequence predictions (first 10 states): {predictions[0][:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfb88d",
   "metadata": {},
   "source": [
    "## 5. Testing with Different HMM Types\n",
    "\n",
    "Let's test device movement with other HMM types to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4432d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with MultinomialHMM\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing MultinomialHMM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "multinomial_hmm = MultinomialHMM(\n",
    "    n_states=3,\n",
    "    n_features=4,\n",
    "    n_trials=10,\n",
    "    transitions=Transitions.ERGODIC,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate multinomial data\n",
    "X_mult = torch.randint(0, 4, (100,))\n",
    "X_mult_onehot = 10 * torch.nn.functional.one_hot(X_mult, 4)\n",
    "\n",
    "print(f\"Initial device: {next(multinomial_hmm.parameters()).device}\")\n",
    "\n",
    "# Move to target device\n",
    "multinomial_hmm.to(device)\n",
    "X_mult_device = X_mult_onehot.to(device)\n",
    "\n",
    "print(f\"After .to({device}): {next(multinomial_hmm.parameters()).device}\")\n",
    "\n",
    "# Quick fit\n",
    "multinomial_hmm.fit(X_mult_device, lengths=[50, 50], max_iter=5, n_init=1, verbose=False)\n",
    "print(f\"Training completed on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with PoissonHMM\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing PoissonHMM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "poisson_hmm = PoissonHMM(\n",
    "    n_states=3,\n",
    "    n_features=2,\n",
    "    transitions=Transitions.ERGODIC,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate Poisson data\n",
    "X_poisson = torch.poisson(torch.ones(100, 2) * 3)\n",
    "\n",
    "print(f\"Initial device: {next(poisson_hmm.parameters()).device}\")\n",
    "\n",
    "# Move to target device\n",
    "poisson_hmm.to(device)\n",
    "X_poisson_device = X_poisson.to(device)\n",
    "\n",
    "print(f\"After .to({device}): {next(poisson_hmm.parameters()).device}\")\n",
    "\n",
    "# Quick fit\n",
    "poisson_hmm.fit(X_poisson_device, lengths=[50, 50], max_iter=5, n_init=1, verbose=False)\n",
    "print(f\"Training completed on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with GaussianMixtureHMM\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Testing GaussianMixtureHMM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gmm_hmm = GaussianMixtureHMM(\n",
    "    n_states=2,\n",
    "    n_features=2,\n",
    "    n_components=3,\n",
    "    transitions=Transitions.ERGODIC,\n",
    "    covariance_type=CovarianceType.FULL,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Generate Gaussian mixture data\n",
    "X_gmm = torch.randn(100, 2)\n",
    "\n",
    "print(f\"Initial device: {next(gmm_hmm.parameters()).device}\")\n",
    "\n",
    "# Move to target device\n",
    "gmm_hmm.to(device)\n",
    "X_gmm_device = X_gmm.to(device)\n",
    "\n",
    "print(f\"After .to({device}): {next(gmm_hmm.parameters()).device}\")\n",
    "\n",
    "# Quick fit\n",
    "gmm_hmm.fit(X_gmm_device, lengths=[50, 50], max_iter=5, n_init=1, verbose=False)\n",
    "print(f\"Training completed on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987e911",
   "metadata": {},
   "source": [
    "## 6. Save and Load Model Across Devices\n",
    "\n",
    "You can save a model trained on one device and load it on another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fb1cb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee9a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd869e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chadhmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
